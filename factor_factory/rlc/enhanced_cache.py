"""
Enhanced Caching System for Program Evaluation

MCTSì™€ ë°±í…ŒìŠ¤íŠ¸ì—ì„œ ë™ì¼í•œ í”„ë¡œê·¸ë¨ì˜ ì¤‘ë³µ í‰ê°€ë¥¼ ë°©ì§€í•˜ê³ 
ì„±ëŠ¥ì„ ëŒ€í­ í–¥ìƒì‹œí‚¤ëŠ” ìºì‹œ ì‹œìŠ¤í…œ
"""

from __future__ import annotations
import hashlib
import pickle
import time
from functools import lru_cache
from typing import Dict, Any, Optional, Tuple
import numpy as np
import pandas as pd
from pathlib import Path
import logging


class FastProgramCache:
    """ê³ ì† í”„ë¡œê·¸ë¨ ìºì‹œ - ë©”ëª¨ë¦¬ + ë””ìŠ¤í¬ í•˜ì´ë¸Œë¦¬ë“œ"""
    
    def __init__(self, 
                 memory_size: int = 4096,     # ë©”ëª¨ë¦¬ ìºì‹œ í¬ê¸°
                 disk_cache_dir: str = "cache_disk",  # ë””ìŠ¤í¬ ìºì‹œ ë””ë ‰í† ë¦¬
                 enable_disk: bool = True):    # ë””ìŠ¤í¬ ìºì‹œ í™œì„±í™”
        
        self.memory_size = memory_size
        self.enable_disk = enable_disk
        
        # ë©”ëª¨ë¦¬ ìºì‹œ
        self._memory_cache = {}
        self._access_order = []
        
        # ë””ìŠ¤í¬ ìºì‹œ
        if enable_disk:
            self.disk_dir = Path(disk_cache_dir)
            self.disk_dir.mkdir(exist_ok=True)
        
        # í†µê³„
        self.stats = {
            'memory_hits': 0,
            'disk_hits': 0,
            'misses': 0,
            'total_requests': 0,
            'save_time': 0.0,
            'load_time': 0.0
        }
        
        logging.info(f"âœ… FastProgramCache ì´ˆê¸°í™” (ë©”ëª¨ë¦¬: {memory_size}, ë””ìŠ¤í¬: {enable_disk})")
    
    def _get_cache_key(self, tokens: list[int], data_hash: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„± - í† í°ê³¼ ë°ì´í„° í•´ì‹œ ì¡°í•©"""
        token_str = "_".join(map(str, tokens))
        return f"{token_str}_{data_hash}"
    
    def _get_data_hash(self, df: pd.DataFrame) -> str:
        """ë°ì´í„° í•´ì‹œ ìƒì„± - ë¹ ë¥¸ í•´ì‹œ í•¨ìˆ˜ ì‚¬ìš©"""
        # DataFrameì˜ í•µì‹¬ ì •ë³´ë¡œ í•´ì‹œ ìƒì„±
        key_data = (
            df.shape,
            tuple(df.columns),
            df.index[0] if len(df) > 0 else 0,
            df.index[-1] if len(df) > 0 else 0,
            df.iloc[0].sum() if len(df) > 0 else 0,
            df.iloc[-1].sum() if len(df) > 0 else 0
        )
        return str(hash(key_data))
    
    def _get_disk_path(self, cache_key: str) -> Path:
        """ë””ìŠ¤í¬ ìºì‹œ íŒŒì¼ ê²½ë¡œ"""
        # í‚¤ë¥¼ í•´ì‹œí•´ì„œ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± (collision ë°©ì§€)
        key_hash = hashlib.md5(cache_key.encode()).hexdigest()
        subdir = key_hash[:2]  # ì²« 2ê¸€ìë¡œ ì„œë¸Œë””ë ‰í† ë¦¬
        return self.disk_dir / subdir / f"{key_hash}.pkl"
    
    def get(self, tokens: list[int], df: pd.DataFrame) -> Optional[pd.Series]:
        """ìºì‹œì—ì„œ ê²°ê³¼ ì¡°íšŒ"""
        self.stats['total_requests'] += 1
        
        cache_key = self._get_cache_key(tokens, self._get_data_hash(df))
        
        # 1. ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
        if cache_key in self._memory_cache:
            self.stats['memory_hits'] += 1
            # LRU ì—…ë°ì´íŠ¸
            self._access_order.remove(cache_key)
            self._access_order.append(cache_key)
            return self._memory_cache[cache_key].copy()
        
        # 2. ë””ìŠ¤í¬ ìºì‹œ í™•ì¸
        if self.enable_disk:
            disk_path = self._get_disk_path(cache_key)
            if disk_path.exists():
                try:
                    start_time = time.time()
                    with open(disk_path, 'rb') as f:
                        result = pickle.load(f)
                    
                    self.stats['load_time'] += time.time() - start_time
                    self.stats['disk_hits'] += 1
                    
                    # ë©”ëª¨ë¦¬ ìºì‹œì—ë„ ì €ì¥
                    self._put_memory(cache_key, result)
                    return result.copy()
                    
                except Exception as e:
                    logging.warning(f"ë””ìŠ¤í¬ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 3. ìºì‹œ ë¯¸ìŠ¤
        self.stats['misses'] += 1
        return None
    
    def put(self, tokens: list[int], df: pd.DataFrame, result: pd.Series):
        """ìºì‹œì— ê²°ê³¼ ì €ì¥"""
        cache_key = self._get_cache_key(tokens, self._get_data_hash(df))
        
        # ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥
        self._put_memory(cache_key, result)
        
        # ë””ìŠ¤í¬ ìºì‹œì— ì €ì¥ (ë¹„ë™ê¸°ì ìœ¼ë¡œ)
        if self.enable_disk:
            self._put_disk(cache_key, result)
    
    def _put_memory(self, cache_key: str, result: pd.Series):
        """ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥"""
        # ìºì‹œ í¬ê¸° ì´ˆê³¼ ì‹œ LRU ì œê±°
        if len(self._memory_cache) >= self.memory_size and cache_key not in self._memory_cache:
            oldest_key = self._access_order.pop(0)
            del self._memory_cache[oldest_key]
        
        self._memory_cache[cache_key] = result.copy()
        if cache_key in self._access_order:
            self._access_order.remove(cache_key)
        self._access_order.append(cache_key)
    
    def _put_disk(self, cache_key: str, result: pd.Series):
        """ë””ìŠ¤í¬ ìºì‹œì— ì €ì¥"""
        try:
            start_time = time.time()
            disk_path = self._get_disk_path(cache_key)
            disk_path.parent.mkdir(exist_ok=True, parents=True)
            
            with open(disk_path, 'wb') as f:
                pickle.dump(result, f, protocol=pickle.HIGHEST_PROTOCOL)
            
            self.stats['save_time'] += time.time() - start_time
            
        except Exception as e:
            logging.warning(f"ë””ìŠ¤í¬ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def clear(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        self._memory_cache.clear()
        self._access_order.clear()
        
        if self.enable_disk and self.disk_dir.exists():
            import shutil
            shutil.rmtree(self.disk_dir)
            self.disk_dir.mkdir(exist_ok=True)
        
        # í†µê³„ ì´ˆê¸°í™”
        for key in self.stats:
            self.stats[key] = 0
    
    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        total = self.stats['total_requests']
        if total == 0:
            return self.stats
        
        hit_rate = (self.stats['memory_hits'] + self.stats['disk_hits']) / total
        memory_rate = self.stats['memory_hits'] / total
        disk_rate = self.stats['disk_hits'] / total
        
        return {
            **self.stats,
            'hit_rate': hit_rate,
            'memory_hit_rate': memory_rate,
            'disk_hit_rate': disk_rate,
            'memory_size': len(self._memory_cache),
            'avg_load_time': self.stats['load_time'] / max(1, self.stats['disk_hits']),
            'avg_save_time': self.stats['save_time'] / max(1, self.stats['total_requests'])
        }


class BacktestCache:
    """ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìºì‹œ - ë©”íŠ¸ë¦­ê¹Œì§€ í¬í•¨"""
    
    def __init__(self, cache_size: int = 1024):
        self.cache_size = cache_size
        self._cache = {}
        self._access_order = []
        
        self.stats = {
            'hits': 0,
            'misses': 0,
            'total_requests': 0
        }
    
    def _get_key(self, signal_hash: str, price_hash: str, commission: float, slippage: float) -> str:
        """ë°±í…ŒìŠ¤íŠ¸ ìºì‹œ í‚¤ ìƒì„±"""
        return f"{signal_hash}_{price_hash}_{commission}_{slippage}"
    
    def _get_series_hash(self, series: pd.Series) -> str:
        """Series í•´ì‹œ ìƒì„±"""
        return str(hash(tuple([
            series.shape[0],
            series.iloc[0] if len(series) > 0 else 0,
            series.iloc[-1] if len(series) > 0 else 0,
            series.sum(),
            series.std()
        ])))
    
    def get(self, signal: pd.Series, price: pd.Series, 
            commission: float, slippage: float) -> Optional[Tuple[pd.Series, pd.Series, Dict]]:
        """ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¡°íšŒ"""
        self.stats['total_requests'] += 1
        
        key = self._get_key(
            self._get_series_hash(signal),
            self._get_series_hash(price),
            commission, slippage
        )
        
        if key in self._cache:
            self.stats['hits'] += 1
            # LRU ì—…ë°ì´íŠ¸
            self._access_order.remove(key)
            self._access_order.append(key)
            
            cached_data = self._cache[key]
            return (
                cached_data['equity'].copy(),
                cached_data['pnl'].copy(),
                cached_data['metrics'].copy()
            )
        
        self.stats['misses'] += 1
        return None
    
    def put(self, signal: pd.Series, price: pd.Series, 
            commission: float, slippage: float,
            equity: pd.Series, pnl: pd.Series, metrics: Dict):
        """ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥"""
        key = self._get_key(
            self._get_series_hash(signal),
            self._get_series_hash(price),
            commission, slippage
        )
        
        # ìºì‹œ í¬ê¸° ì´ˆê³¼ ì‹œ LRU ì œê±°
        if len(self._cache) >= self.cache_size and key not in self._cache:
            oldest_key = self._access_order.pop(0)
            del self._cache[oldest_key]
        
        self._cache[key] = {
            'equity': equity.copy(),
            'pnl': pnl.copy(),
            'metrics': metrics.copy()
        }
        
        if key in self._access_order:
            self._access_order.remove(key)
        self._access_order.append(key)
    
    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„"""
        total = self.stats['total_requests']
        hit_rate = self.stats['hits'] / total if total > 0 else 0
        
        return {
            **self.stats,
            'hit_rate': hit_rate,
            'cache_size': len(self._cache)
        }


# ì „ì—­ ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ë“¤
_fast_program_cache = None
_backtest_cache = None

def get_fast_program_cache(memory_size: int = 4096, 
                          enable_disk: bool = True) -> FastProgramCache:
    """ì „ì—­ ê³ ì† í”„ë¡œê·¸ë¨ ìºì‹œ ë°˜í™˜"""
    global _fast_program_cache
    if _fast_program_cache is None:
        _fast_program_cache = FastProgramCache(memory_size, enable_disk=enable_disk)
    return _fast_program_cache

def get_backtest_cache(cache_size: int = 1024) -> BacktestCache:
    """ì „ì—­ ë°±í…ŒìŠ¤íŠ¸ ìºì‹œ ë°˜í™˜"""
    global _backtest_cache
    if _backtest_cache is None:
        _backtest_cache = BacktestCache(cache_size)
    return _backtest_cache

def clear_all_caches():
    """ëª¨ë“  ìºì‹œ ì´ˆê¸°í™”"""
    global _fast_program_cache, _backtest_cache
    
    if _fast_program_cache:
        _fast_program_cache.clear()
    if _backtest_cache:
        _backtest_cache._cache.clear()
        _backtest_cache._access_order.clear()
    
    logging.info("ğŸ§¹ ëª¨ë“  ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤")

def get_cache_statistics() -> Dict[str, Any]:
    """ì „ì²´ ìºì‹œ í†µê³„ ë°˜í™˜"""
    stats = {}
    
    if _fast_program_cache:
        stats['program_cache'] = _fast_program_cache.get_stats()
    
    if _backtest_cache:
        stats['backtest_cache'] = _backtest_cache.get_stats()
    
    return stats
